{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 619, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-43a01a0bfc59>\", line 4, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2326, in run_line_magic\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui.lower() if isinstance(args.gui, str) else args.gui)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 601, in enable_matplotlib\n",
      "    gui, backend = super(ZMQInteractiveShell, self).enable_matplotlib(gui)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3431, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 322, in activate_matplotlib\n",
      "    plt.switch_backend(backend)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 229, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import sys\n",
      "/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/tacotron2-gst/plotting_utils.py:2: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 619, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-43a01a0bfc59>\", line 4, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2326, in run_line_magic\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui.lower() if isinstance(args.gui, str) else args.gui)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 601, in enable_matplotlib\n",
      "    gui, backend = super(ZMQInteractiveShell, self).enable_matplotlib(gui)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3431, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 322, in activate_matplotlib\n",
      "    plt.switch_backend(backend)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 229, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/root/anaconda3/envs/tf13/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use(\"Agg\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('/workspace/tacotron2-gst/hifi_gan/')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "#import glow\n",
    "import torch\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from utils import load_wav_to_torch\n",
    "from tqdm import tqdm\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT\n",
    "from train import load_model\n",
    "from text import text_to_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/tacotron2-gst\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/anaconda3/envs/tf13/lib/python36.zip', '/root/anaconda3/envs/tf13/lib/python3.6', '/root/anaconda3/envs/tf13/lib/python3.6/lib-dynload', '', '/root/anaconda3/envs/tf13/lib/python3.6/site-packages', '/root/anaconda3/envs/tf13/lib/python3.6/site-packages/IPython/extensions', '/root/.ipython', '/workspace/tacotron2-gst/hifi_gan/']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hparams = create_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = TacotronSTFT(\n",
    "            hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
    "            hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
    "            hparams.mel_fmax)\n",
    "\n",
    "def load_mel(path):\n",
    "    audio, sampling_rate = load_wav_to_torch(path)\n",
    "    if sampling_rate != hparams.sampling_rate:\n",
    "        raise ValueError(\"{} SR doesn't match target {} SR\".format(\n",
    "            sampling_rate, stft.sampling_rate))\n",
    "    audio_norm = audio / hparams.max_wav_value\n",
    "    audio_norm = audio_norm.unsqueeze(0)\n",
    "    audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
    "    melspec = stft.mel_spectrogram(audio_norm)\n",
    "    melspec = melspec.cuda()\n",
    "    return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(data, aspect='auto', origin='bottom', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/workspace/tacotron2-gst/skt_multi_outdir/checkpoint_212500\"\n",
    "model = load_model(hparams)\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# waveglow_path = '/workspace/tacotron2-gst/waveglow_520000'\n",
    "# waveglow = torch.load(waveglow_path)['model']\n",
    "# waveglow.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextEncoder(text):\n",
    "    sequence = np.array(text_to_sequence(text, ['korean_cleaners']))[None, :]\n",
    "    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
    "    inputs = model.parse_input(sequence)\n",
    "    embedded_inputs = model.embedding(inputs).transpose(1,2)\n",
    "    transcript_outputs = model.encoder.inference(embedded_inputs)\n",
    "    \n",
    "    return transcript_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoder(encoder_outputs):\n",
    "    decoder_input = model.decoder.get_go_frame(encoder_outputs)\n",
    "    model.decoder.initialize_decoder_states(encoder_outputs, mask=None)\n",
    "    mel_outputs, gate_outputs, alignments = [], [], []\n",
    "\n",
    "    while True:\n",
    "        decoder_input = model.decoder.prenet(decoder_input)\n",
    "        mel_output, gate_output, alignment = model.decoder.decode(decoder_input)\n",
    "\n",
    "        mel_outputs += [mel_output]\n",
    "        gate_outputs += [gate_output]\n",
    "        alignments += [alignment]\n",
    "\n",
    "        if torch.sigmoid(gate_output.data) > hparams.gate_threshold:\n",
    "            print(torch.sigmoid(gate_output.data), gate_output.data)\n",
    "            break\n",
    "        if len(mel_outputs) == hparams.max_decoder_steps:\n",
    "            print(\"Warning! Reached max decoder steps\")\n",
    "            break\n",
    "\n",
    "        decoder_input = mel_output\n",
    "\n",
    "    mel_outputs, gate_outputs, alignments = model.decoder.parse_decoder_outputs(\n",
    "        mel_outputs, gate_outputs, alignments)\n",
    "    mel_outputs_postnet = model.postnet(mel_outputs)\n",
    "    mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "    with torch.no_grad():\n",
    "        synth = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "        \n",
    "    return synth, mel_outputs_postnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition on Ref Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mels_by_ref_audio(text, ref_audio):\n",
    "    transcript_outputs = TextEncoder(text)\n",
    "    print(\"ref_audio\")\n",
    "    ipd.display(ipd.Audio(ref_audio, rate=hparams.sampling_rate))\n",
    "    ref_audio_mel = load_mel(ref_audio)\n",
    "    ipd.display(plot_data(ref_audio_mel.data.cpu().numpy()[0]))\n",
    "    latent_vector = model.gst(ref_audio_mel)\n",
    "    latent_vector = latent_vector.expand_as(transcript_outputs)\n",
    "\n",
    "    encoder_outputs = transcript_outputs + latent_vector\n",
    "    \n",
    "    synth, mel_outputs = Decoder(encoder_outputs)\n",
    "    \n",
    "    ipd.display(ipd.Audio(synth[0].data.cpu().numpy(), rate=hparams.sampling_rate))\n",
    "    ipd.display(plot_data(mel_outputs.data.cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = \"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\n",
    "#ref_wav = \"/DATA2/jinhan/KoreanEmotionSpeech/wav/ang/ang_00000100.wav\"\n",
    "ref_wav = \"/workspace/data/Emo_kor/acriil_ang_00000100.wav\"\n",
    "generate_mels_by_ref_audio(text, ref_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\n",
    "#ref_wav = \"/DATA2/jinhan/KoreanEmotionSpeech/wav/sad/sad_00000100.wav\"\n",
    "ref_wav = \"/workspace/data/Emo_kor/acriil_sad_00000100.wav\"\n",
    "generate_mels_by_ref_audio(text, ref_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\n",
    "#ref_wav = \"/DATA2/jinhan/KoreanEmotionSpeech/wav/sad/sad_00000100.wav\"\n",
    "ref_wav = \"/workspace/data/Emo_kor/acriil_hap_00000100.wav\"\n",
    "generate_mels_by_ref_audio(text, ref_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\n",
    "#ref_wav = \"/DATA2/jinhan/KoreanEmotionSpeech/wav/sad/sad_00000100.wav\"\n",
    "ref_wav = \"/workspace/data/Emo_kor/acriil_fea_00000100.wav\"\n",
    "generate_mels_by_ref_audio(text, ref_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\n",
    "#ref_wav = \"/DATA2/jinhan/KoreanEmotionSpeech/wav/sad/sad_00000100.wav\"\n",
    "ref_wav = \"/workspace/data/Emo_kor/acriil_sur_00000100.wav\"\n",
    "generate_mels_by_ref_audio(text, ref_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\n",
    "#ref_wav = \"/DATA2/jinhan/KoreanEmotionSpeech/wav/sad/sad_00000100.wav\"\n",
    "ref_wav = \"/workspace/data/Emo_kor/acriil_dis_00000100.wav\"\n",
    "generate_mels_by_ref_audio(text, ref_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition on Style Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mels_by_style_tokens(text):\n",
    "    transcript_outputs = TextEncoder(text)\n",
    "    GST = torch.tanh(model.gst.stl.embed)\n",
    "\n",
    "    for idx in range(10):\n",
    "        query = torch.zeros(1, 1, hparams.E//2).cuda()\n",
    "        keys = GST[idx].unsqueeze(0).expand(1,-1,-1)\n",
    "        style_emb = model.gst.stl.attention(query, keys)\n",
    "        encoder_outputs = transcript_outputs + style_emb\n",
    "\n",
    "        synth, mel_outputs = Decoder(encoder_outputs)\n",
    "\n",
    "        print(\"token {}\".format(idx))\n",
    "        ipd.display(ipd.Audio(synth[0].data.cpu().numpy(), rate=hparams.sampling_rate))\n",
    "        ipd.display(plot_data(mel_outputs.data.cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Reached max decoder steps\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'waveglow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cff0f6116010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_mels_by_style_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3cdcc554696e>\u001b[0m in \u001b[0;36mgenerate_mels_by_style_tokens\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscript_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstyle_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msynth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"token {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1dceaf197d54>\u001b[0m in \u001b[0;36mDecoder\u001b[0;34m(encoder_outputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0msynth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveglow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_outputs_postnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msynth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_outputs_postnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'waveglow' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"이 모델을 이용하면 같은 문장을 여러가지 스타일로 말할 수 있습니다.\"\n",
    "generate_mels_by_style_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
